{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle , resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "        # 建立输入节点与输出节点之间的连接\n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "\n",
    "        self.value = None\n",
    "\n",
    "        self.gradients = {}\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def backward(self):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入节点类\n",
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None):\n",
    "        # 如果有输入值，则输入节点接收该值作为它自身的属性\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {self:0} \n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Node):\n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隐藏层线性组合类\n",
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "        \n",
    "    def backward(self):\n",
    "\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "\n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value   \n",
    "        self.value = self._sigmoid(self.x)\n",
    "\n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        \n",
    "        \n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]  \n",
    "\n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - a\n",
    "\n",
    "        self.value = np.mean(self.diff**2)\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(outputnode, graph):\n",
    "   \n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "\n",
    "    for n in  graph[::-1]:\n",
    "        n.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拓扑排序\n",
    "def topological_sort(feed_dict):\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_update(trainables, learning_rate=1e-2):\n",
    "\n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ , y_ = data['data'],data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "print(X_.shape)\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = (X_ - np.mean(X_ , axis = 0)) / np.std(X_ , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接下来需要对神经网络的参数进行初始化 神经网络的参数初始化一般不为0\n",
    "# 因为当参数初始化为0时会使得L1层隐藏单元完全对称也就是都是相同地  这样是没有意义地\n",
    "# 故神经网络在参数初始化时一般随机选择一组具有高斯正态分布的数据\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features,n_hidden)  # (13,10)\n",
    "b1_ = np.random.randn(n_hidden)             # (10,)\n",
    "W2_ = np.random.randn(n_hidden,1)           # (10,1)\n",
    "b2_ = np.zeros(1)                           # (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化输入节点作为Input类的对象\n",
    "X  , y  = Input() , Input()\n",
    "W1 , b1 = Input() , Input()\n",
    "W2 , b2 = Input() , Input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Linear(X, W1, b1) # 实例化Linear类并传入X,W1,b1三个对象 \n",
    "s1 = Sigmoid(l1) \n",
    "l2 = Linear(s1,W2,b2)\n",
    "cost = MSE(y, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': [], 'outputs': [<__main__.Linear object at 0x1a3d455898>], 'value': None, 'gradients': {}}\n",
      "{'inputs': [], 'outputs': [<__main__.MSE object at 0x1a3d455908>], 'value': None, 'gradients': {}}\n",
      "{'inputs': [], 'outputs': [<__main__.Linear object at 0x1a3d455898>], 'value': None, 'gradients': {}}\n",
      "{'inputs': [], 'outputs': [<__main__.Linear object at 0x1a3d455898>], 'value': None, 'gradients': {}}\n",
      "{'inputs': [], 'outputs': [<__main__.Linear object at 0x1a3d4555f8>], 'value': None, 'gradients': {}}\n",
      "{'inputs': [], 'outputs': [<__main__.Linear object at 0x1a3d4555f8>], 'value': None, 'gradients': {}}\n"
     ]
    }
   ],
   "source": [
    "print(X.__dict__)\n",
    "print(y.__dict__)\n",
    "print(W1.__dict__)\n",
    "print(b1.__dict__)\n",
    "print(W2.__dict__)\n",
    "print(b2.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "# Total number of examples\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples = 506\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of examples = {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Input object at 0x1a3d3df828>, <__main__.Input object at 0x1a3d450a58>, <__main__.Input object at 0x1a3d3df860>, <__main__.Input object at 0x1a3d3df278>, <__main__.Input object at 0x1a3d3ed898>, <__main__.Input object at 0x1a3d450898>, <__main__.Linear object at 0x1a3d455898>, <__main__.Sigmoid object at 0x1a3d455780>, <__main__.Linear object at 0x1a3d4555f8>, <__main__.MSE object at 0x1a3d455908>]\n"
     ]
    }
   ],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(outputNode,graph):\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "    return outputNode.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 146.389\n",
      "Epoch: 101, Loss: 5.867\n",
      "Epoch: 201, Loss: 5.394\n",
      "Epoch: 301, Loss: 3.376\n",
      "Epoch: 401, Loss: 3.257\n",
      "Epoch: 501, Loss: 3.464\n",
      "Epoch: 601, Loss: 3.717\n",
      "Epoch: 701, Loss: 3.004\n",
      "Epoch: 801, Loss: 3.244\n",
      "Epoch: 901, Loss: 3.274\n",
      "Epoch: 1001, Loss: 3.432\n",
      "Epoch: 1101, Loss: 3.203\n",
      "Epoch: 1201, Loss: 2.895\n",
      "Epoch: 1301, Loss: 3.258\n",
      "Epoch: 1401, Loss: 2.802\n",
      "Epoch: 1501, Loss: 3.314\n",
      "Epoch: 1601, Loss: 3.154\n",
      "Epoch: 1701, Loss: 2.945\n",
      "Epoch: 1801, Loss: 3.167\n",
      "Epoch: 1901, Loss: 2.818\n",
      "Epoch: 2001, Loss: 2.670\n",
      "Epoch: 2101, Loss: 2.507\n",
      "Epoch: 2201, Loss: 2.563\n",
      "Epoch: 2301, Loss: 2.390\n",
      "Epoch: 2401, Loss: 2.482\n",
      "Epoch: 2501, Loss: 2.634\n",
      "Epoch: 2601, Loss: 2.793\n",
      "Epoch: 2701, Loss: 2.711\n",
      "Epoch: 2801, Loss: 2.481\n",
      "Epoch: 2901, Loss: 2.732\n",
      "Epoch: 3001, Loss: 2.963\n",
      "Epoch: 3101, Loss: 2.519\n",
      "Epoch: 3201, Loss: 2.443\n",
      "Epoch: 3301, Loss: 2.491\n",
      "Epoch: 3401, Loss: 2.622\n",
      "Epoch: 3501, Loss: 2.628\n",
      "Epoch: 3601, Loss: 2.453\n",
      "Epoch: 3701, Loss: 2.921\n",
      "Epoch: 3801, Loss: 2.703\n",
      "Epoch: 3901, Loss: 2.912\n",
      "Epoch: 4001, Loss: 2.578\n",
      "Epoch: 4101, Loss: 2.501\n",
      "Epoch: 4201, Loss: 2.557\n",
      "Epoch: 4301, Loss: 2.334\n",
      "Epoch: 4401, Loss: 2.398\n",
      "Epoch: 4501, Loss: 2.378\n",
      "Epoch: 4601, Loss: 2.954\n",
      "Epoch: 4701, Loss: 2.324\n",
      "Epoch: 4801, Loss: 2.432\n",
      "Epoch: 4901, Loss: 2.593\n"
     ]
    }
   ],
   "source": [
    "# Step 4\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "        _ = None\n",
    "        forward_and_backward(_, graph) # set output node not important.\n",
    "\n",
    "        # Step 3\n",
    "        rate = 0.01\n",
    "    \n",
    "        sgd_update(trainables, rate)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3d5605f8>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)),losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64,activation='sigmoid',input_dim=13))\n",
    "model.add(Dense(units=30,activation='sigmoid',input_dim=64))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "506/506 [==============================] - 0s 360us/step - loss: 156.9517 - mse: 156.9517\n",
      "Epoch 2/2000\n",
      "506/506 [==============================] - 0s 138us/step - loss: 68.5101 - mse: 68.5101\n",
      "Epoch 3/2000\n",
      "506/506 [==============================] - 0s 104us/step - loss: 49.8530 - mse: 49.8530\n",
      "Epoch 4/2000\n",
      "506/506 [==============================] - 0s 79us/step - loss: 37.7258 - mse: 37.7258\n",
      "Epoch 5/2000\n",
      "506/506 [==============================] - 0s 72us/step - loss: 30.7509 - mse: 30.7509\n",
      "Epoch 6/2000\n",
      "506/506 [==============================] - 0s 167us/step - loss: 26.1035 - mse: 26.1035\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_, y_, epochs=2000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
